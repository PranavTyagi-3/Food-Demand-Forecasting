{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewOzw9TWGFAm"
      },
      "source": [
        "**IMPORTING ALL DEPENDENCIES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z_UOXBXGGGeK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import  RandomizedSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "gb_regressor = GradientBoostingRegressor()\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgt5DFtJGOiq"
      },
      "source": [
        "**loading dataset from csv**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "A7Tpp8tIGW_c"
      },
      "outputs": [],
      "source": [
        "\n",
        "train=pd.read_csv('train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "w7hnDbsH9lZN"
      },
      "outputs": [],
      "source": [
        "test=pd.read_csv('/content/drive/MyDrive/datasets/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "K17TXu0t9l8x"
      },
      "outputs": [],
      "source": [
        "meal=pd.read_csv('meal_info.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vtM1eMq891bm"
      },
      "outputs": [],
      "source": [
        "train=train.merge(meal, on='meal_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PyPZt6VA9S0q",
        "outputId": "a218587f-6445-4d99-e70c-f514fcc950ad"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>week</th>\n",
              "      <th>center_id</th>\n",
              "      <th>meal_id</th>\n",
              "      <th>checkout_price</th>\n",
              "      <th>base_price</th>\n",
              "      <th>emailer_for_promotion</th>\n",
              "      <th>homepage_featured</th>\n",
              "      <th>num_orders</th>\n",
              "      <th>category</th>\n",
              "      <th>cuisine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1379560</td>\n",
              "      <td>1</td>\n",
              "      <td>55</td>\n",
              "      <td>1885</td>\n",
              "      <td>136.83</td>\n",
              "      <td>152.29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>177</td>\n",
              "      <td>Beverages</td>\n",
              "      <td>Thai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1040403</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>1885</td>\n",
              "      <td>136.83</td>\n",
              "      <td>136.83</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1498</td>\n",
              "      <td>Beverages</td>\n",
              "      <td>Thai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1103215</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>1885</td>\n",
              "      <td>136.83</td>\n",
              "      <td>136.83</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>959</td>\n",
              "      <td>Beverages</td>\n",
              "      <td>Thai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1034383</td>\n",
              "      <td>1</td>\n",
              "      <td>83</td>\n",
              "      <td>1885</td>\n",
              "      <td>121.31</td>\n",
              "      <td>120.31</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1025</td>\n",
              "      <td>Beverages</td>\n",
              "      <td>Thai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1118999</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>1885</td>\n",
              "      <td>114.52</td>\n",
              "      <td>113.52</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>445</td>\n",
              "      <td>Beverages</td>\n",
              "      <td>Thai</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  week  center_id  meal_id  checkout_price  base_price  \\\n",
              "0  1379560     1         55     1885          136.83      152.29   \n",
              "1  1040403     1         24     1885          136.83      136.83   \n",
              "2  1103215     1         11     1885          136.83      136.83   \n",
              "3  1034383     1         83     1885          121.31      120.31   \n",
              "4  1118999     1         32     1885          114.52      113.52   \n",
              "\n",
              "   emailer_for_promotion  homepage_featured  num_orders   category cuisine  \n",
              "0                      0                  0         177  Beverages    Thai  \n",
              "1                      0                  0        1498  Beverages    Thai  \n",
              "2                      0                  0         959  Beverages    Thai  \n",
              "3                      0                  1        1025  Beverages    Thai  \n",
              "4                      0                  1         445  Beverages    Thai  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fcOvFwJW-FuU"
      },
      "outputs": [],
      "source": [
        "center_id = 55\n",
        "meal_id = 1993"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qmHDdoi0H62k"
      },
      "outputs": [],
      "source": [
        "def preprocessreg(train):\n",
        "  train_df = train[train['center_id']==center_id]\n",
        "  train_df = train_df[train_df['meal_id']==meal_id]\n",
        "\n",
        "  categorical_cols = ['category', 'cuisine']\n",
        "  from sklearn.preprocessing import LabelEncoder\n",
        "  label_encoder = LabelEncoder()\n",
        "  for column in categorical_cols:\n",
        "    train_df[column] = label_encoder.fit_transform(train_df[column])\n",
        "\n",
        "  train_df.isnull().sum()\n",
        "\n",
        "  train_df = train_df.reset_index()\n",
        "\n",
        "  return train_df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_df=preprocessreg(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 145 entries, 0 to 144\n",
            "Data columns (total 12 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   index                  145 non-null    int64  \n",
            " 1   id                     145 non-null    int64  \n",
            " 2   week                   145 non-null    int64  \n",
            " 3   center_id              145 non-null    int64  \n",
            " 4   meal_id                145 non-null    int64  \n",
            " 5   checkout_price         145 non-null    float64\n",
            " 6   base_price             145 non-null    float64\n",
            " 7   emailer_for_promotion  145 non-null    int64  \n",
            " 8   homepage_featured      145 non-null    int64  \n",
            " 9   num_orders             145 non-null    int64  \n",
            " 10  category               145 non-null    int32  \n",
            " 11  cuisine                145 non-null    int32  \n",
            "dtypes: float64(2), int32(2), int64(8)\n",
            "memory usage: 12.6 KB\n"
          ]
        }
      ],
      "source": [
        "train_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvFDwYK68Mjn"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>week</th>\n",
              "      <th>center_id</th>\n",
              "      <th>meal_id</th>\n",
              "      <th>checkout_price</th>\n",
              "      <th>base_price</th>\n",
              "      <th>emailer_for_promotion</th>\n",
              "      <th>homepage_featured</th>\n",
              "      <th>num_orders</th>\n",
              "      <th>category</th>\n",
              "      <th>cuisine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11092</td>\n",
              "      <td>1466964</td>\n",
              "      <td>1</td>\n",
              "      <td>55</td>\n",
              "      <td>1993</td>\n",
              "      <td>136.83</td>\n",
              "      <td>135.83</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>270</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11169</td>\n",
              "      <td>1035555</td>\n",
              "      <td>2</td>\n",
              "      <td>55</td>\n",
              "      <td>1993</td>\n",
              "      <td>133.89</td>\n",
              "      <td>133.89</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>121</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11246</td>\n",
              "      <td>1282652</td>\n",
              "      <td>3</td>\n",
              "      <td>55</td>\n",
              "      <td>1993</td>\n",
              "      <td>134.86</td>\n",
              "      <td>133.86</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>258</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11323</td>\n",
              "      <td>1066744</td>\n",
              "      <td>4</td>\n",
              "      <td>55</td>\n",
              "      <td>1993</td>\n",
              "      <td>134.89</td>\n",
              "      <td>133.89</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>82</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11400</td>\n",
              "      <td>1115779</td>\n",
              "      <td>5</td>\n",
              "      <td>55</td>\n",
              "      <td>1993</td>\n",
              "      <td>147.50</td>\n",
              "      <td>145.50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>81</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index       id  week  center_id  meal_id  checkout_price  base_price  \\\n",
              "0  11092  1466964     1         55     1993          136.83      135.83   \n",
              "1  11169  1035555     2         55     1993          133.89      133.89   \n",
              "2  11246  1282652     3         55     1993          134.86      133.86   \n",
              "3  11323  1066744     4         55     1993          134.89      133.89   \n",
              "4  11400  1115779     5         55     1993          147.50      145.50   \n",
              "\n",
              "   emailer_for_promotion  homepage_featured  num_orders  category  cuisine  \n",
              "0                      0                  0         270         0        0  \n",
              "1                      0                  0         121         0        0  \n",
              "2                      0                  0         258         0        0  \n",
              "3                      0                  0          82         0        0  \n",
              "4                      0                  0          81         0        0  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooYUjcN31S3g"
      },
      "source": [
        "#**XB REGRESSOR**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1Q9dy9NzlRu",
        "outputId": "d1e8087e-c0dd-4321-8493-1bc60e92a1ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error (No Hyperparameter Tuning):  94.08653680209456\n",
            "Best Parameters (Grid Search): {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
            "Mean Absolute Error (Grid Search): 78.68997244999326\n",
            "Best Parameters (Random Search): {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1}\n",
            "Mean Absolute Error (Random Search): 83.04240733179553\n"
          ]
        }
      ],
      "source": [
        "# xb regressor\n",
        "def xgbtrain(train_df):\n",
        "  # Train-test split\n",
        "  import pandas as pd\n",
        "  from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "  from xgboost import XGBRegressor\n",
        "  from sklearn import metrics\n",
        "  X = train_df.drop(columns=['num_orders', 'id', 'meal_id', 'center_id', 'index'], axis=1)\n",
        "  Y = train_df['num_orders']\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
        "\n",
        "  # Define the XGBoost model\n",
        "  model = XGBRegressor()\n",
        "\n",
        "  # Train the model without hyperparameter tuning\n",
        "  model.fit(X_train, Y_train)\n",
        "  training_data_prediction = model.predict(X_train)\n",
        "  test_data_prediction = model.predict(X_test)\n",
        "  score_2 = metrics.mean_absolute_error(Y_test, test_data_prediction)\n",
        "  print('Mean Absolute Error (No Hyperparameter Tuning): ', score_2)\n",
        "\n",
        "  # Hyperparameter tuning using Grid Search\n",
        "  param_grid = {\n",
        "      'learning_rate': [0.01, 0.1, 0.2],\n",
        "      'n_estimators': [100, 200, 300],\n",
        "      'max_depth': [3, 4, 5]\n",
        "  }\n",
        "\n",
        "  grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='neg_mean_absolute_error')\n",
        "  grid_search.fit(X_train, Y_train)\n",
        "\n",
        "  best_params_grid = grid_search.best_params_\n",
        "  print('Best Parameters (Grid Search):', best_params_grid)\n",
        "\n",
        "  # Train the model with the best parameters from Grid Search\n",
        "  model_grid = XGBRegressor(**best_params_grid)\n",
        "  model_grid.fit(X_train, Y_train)\n",
        "  test_data_prediction_grid = model_grid.predict(X_test)\n",
        "  score_grid = metrics.mean_absolute_error(Y_test, test_data_prediction_grid)\n",
        "  print('Mean Absolute Error (Grid Search):', score_grid)\n",
        "\n",
        "  # Hyperparameter tuning using Random Search\n",
        "  param_dist = {\n",
        "      'learning_rate': [0.01, 0.1, 0.2],\n",
        "      'n_estimators': [100, 200, 300],\n",
        "      'max_depth': [3, 4, 5]\n",
        "  }\n",
        "\n",
        "  random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=10, cv=3,\n",
        "                                      scoring='neg_mean_absolute_error', random_state=42)\n",
        "  random_search.fit(X_train, Y_train)\n",
        "\n",
        "  best_params_random = random_search.best_params_\n",
        "  print('Best Parameters (Random Search):', best_params_random)\n",
        "\n",
        "  # Train the model with the best parameters from Random Search\n",
        "  model_random = XGBRegressor(**best_params_random)\n",
        "  model_random.fit(X_train, Y_train)\n",
        "  test_data_prediction_random = model_random.predict(X_test)\n",
        "  score_random = metrics.mean_absolute_error(Y_test, test_data_prediction_random)\n",
        "  print('Mean Absolute Error (Random Search):', score_random)\n",
        "\n",
        "xgbtrain(train_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9spwryI1vOj"
      },
      "source": [
        "#**RANDOM FOREST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeYELJ7x1tlU",
        "outputId": "bf232f73-ef2c-4edf-9ec2-3f0c04f574df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error (No Hyperparameter Tuning):  73.3093103448276\n",
            "Best Parameters (Grid Search): {'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Mean Absolute Error (Grid Search): 71.6968750765518\n",
            "Best Parameters (Random Search): {'n_estimators': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': None}\n",
            "Mean Absolute Error (Random Search): 69.35076683087026\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn import metrics\n",
        "\n",
        "def random_forest_train(train_df):\n",
        "    # Train-test split\n",
        "    X = train_df.drop(columns=['num_orders', 'id', 'meal_id', 'center_id', 'index'], axis=1)\n",
        "    Y = train_df['num_orders']\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
        "\n",
        "    # Define the Random Forest model\n",
        "    rf_model = RandomForestRegressor()\n",
        "\n",
        "    # Train the model without hyperparameter tuning\n",
        "    rf_model.fit(X_train, Y_train)\n",
        "    training_data_prediction_rf = rf_model.predict(X_train)\n",
        "    test_data_prediction_rf = rf_model.predict(X_test)\n",
        "    score_rf_2 = metrics.mean_absolute_error(Y_test, test_data_prediction_rf)\n",
        "    print('Mean Absolute Error (No Hyperparameter Tuning): ', score_rf_2)\n",
        "\n",
        "    # Hyperparameter tuning using Grid Search\n",
        "    param_grid_rf = {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20,30],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4]\n",
        "    }\n",
        "\n",
        "    grid_search_rf = GridSearchCV(estimator=rf_model, param_grid=param_grid_rf, cv=3, scoring='neg_mean_absolute_error')\n",
        "    grid_search_rf.fit(X_train, Y_train)\n",
        "\n",
        "    best_params_grid_rf = grid_search_rf.best_params_\n",
        "    print('Best Parameters (Grid Search):', best_params_grid_rf)\n",
        "\n",
        "    # Train the model with the best parameters from Grid Search\n",
        "    rf_model_grid = RandomForestRegressor(**best_params_grid_rf)\n",
        "    rf_model_grid.fit(X_train, Y_train)\n",
        "    test_data_prediction_grid_rf = rf_model_grid.predict(X_test)\n",
        "    score_grid_rf = metrics.mean_absolute_error(Y_test, test_data_prediction_grid_rf)\n",
        "    print('Mean Absolute Error (Grid Search):', score_grid_rf)\n",
        "\n",
        "    # Hyperparameter tuning using Random Search\n",
        "    param_dist_rf = {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4]\n",
        "    }\n",
        "\n",
        "    random_search_rf = RandomizedSearchCV(estimator=rf_model, param_distributions=param_dist_rf, n_iter=10, cv=3,\n",
        "                                          scoring='neg_mean_absolute_error', random_state=42)\n",
        "    random_search_rf.fit(X_train, Y_train)\n",
        "\n",
        "    best_params_random_rf = random_search_rf.best_params_\n",
        "    print('Best Parameters (Random Search):', best_params_random_rf)\n",
        "\n",
        "    # Train the model with the best parameters from Random Search\n",
        "    rf_model_random = RandomForestRegressor(**best_params_random_rf)\n",
        "    rf_model_random.fit(X_train, Y_train)\n",
        "    test_data_prediction_random_rf = rf_model_random.predict(X_test)\n",
        "    score_random_rf = metrics.mean_absolute_error(Y_test, test_data_prediction_random_rf)\n",
        "    print('Mean Absolute Error (Random Search):', score_random_rf)\n",
        "\n",
        "random_forest_train(train_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVQMlODR2a8O"
      },
      "source": [
        "#**DECISION TREE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WGBZKO02din",
        "outputId": "4d200108-6018-41d7-d619-769eebba6b82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error (No Hyperparameter Tuning):  100.96551724137932\n",
            "Best Parameters (Grid Search): {'max_depth': None, 'min_samples_leaf': 5, 'min_samples_split': 20}\n",
            "Mean Absolute Error (Grid Search): 66.90671624971827\n",
            "Best Parameters (Random Search): {'min_samples_split': 10, 'min_samples_leaf': 4, 'max_depth': 5}\n",
            "Mean Absolute Error (Random Search): 68.67422003284072\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn import metrics\n",
        "\n",
        "def decision_tree_train(train_df):\n",
        "    # Train-test split\n",
        "    X = train_df.drop(columns=['num_orders', 'id', 'meal_id', 'center_id', 'index'], axis=1)\n",
        "    Y = train_df['num_orders']\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
        "\n",
        "    # Define the Decision Tree model\n",
        "    model = DecisionTreeRegressor()\n",
        "\n",
        "    # Train the model without hyperparameter tuning\n",
        "    model.fit(X_train, Y_train)\n",
        "    training_data_prediction = model.predict(X_train)\n",
        "    test_data_prediction = model.predict(X_test)\n",
        "    score_2 = metrics.mean_absolute_error(Y_test, test_data_prediction)\n",
        "    print('Mean Absolute Error (No Hyperparameter Tuning): ', score_2)\n",
        "\n",
        "    # Hyperparameter tuning using Grid Search\n",
        "    param_grid = {\n",
        "        'max_depth': [None, 5, 10, 15,20,30],\n",
        "        'min_samples_split': [2, 5, 10,15,20],\n",
        "        'min_samples_leaf': [1, 2, 4,5]\n",
        "    }\n",
        "\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='neg_mean_absolute_error')\n",
        "    grid_search.fit(X_train, Y_train)\n",
        "\n",
        "    best_params_grid = grid_search.best_params_\n",
        "    print('Best Parameters (Grid Search):', best_params_grid)\n",
        "\n",
        "    # Train the model with the best parameters from Grid Search\n",
        "    model_grid = DecisionTreeRegressor(**best_params_grid)\n",
        "    model_grid.fit(X_train, Y_train)\n",
        "    test_data_prediction_grid = model_grid.predict(X_test)\n",
        "    score_grid = metrics.mean_absolute_error(Y_test, test_data_prediction_grid)\n",
        "    print('Mean Absolute Error (Grid Search):', score_grid)\n",
        "\n",
        "    # Hyperparameter tuning using Random Search\n",
        "    param_dist = {\n",
        "        'max_depth': [None, 5, 10, 15],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4]\n",
        "    }\n",
        "\n",
        "    random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=10, cv=3,\n",
        "                                       scoring='neg_mean_absolute_error', random_state=42)\n",
        "    random_search.fit(X_train, Y_train)\n",
        "\n",
        "    best_params_random = random_search.best_params_\n",
        "    print('Best Parameters (Random Search):', best_params_random)\n",
        "\n",
        "    # Train the model with the best parameters from Random Search\n",
        "    model_random = DecisionTreeRegressor(**best_params_random)\n",
        "    model_random.fit(X_train, Y_train)\n",
        "    test_data_prediction_random = model_random.predict(X_test)\n",
        "    score_random = metrics.mean_absolute_error(Y_test, test_data_prediction_random)\n",
        "    print('Mean Absolute Error (Random Search):', score_random)\n",
        "\n",
        "# Call the function with your train_df\n",
        "# decision_tree_train(train_df)\n",
        "decision_tree_train(train_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64tFlAKb3WEp"
      },
      "source": [
        "#**GRADIENT BOOSTING REGRESSOR**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdVm_bBb3VB3",
        "outputId": "911ade55-4b7a-4b5d-d739-c0c484249ad1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error (No Hyperparameter Tuning):  89.18861337468383\n",
            "Best Parameters (Grid Search): {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}\n",
            "Mean Absolute Error (Grid Search): 83.77450189258033\n",
            "Best Parameters (Random Search): {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.01}\n",
            "Mean Absolute Error (Random Search): 79.94266919309469\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn import metrics\n",
        "\n",
        "def gbtrain(train_df):\n",
        "    # Train-test split\n",
        "    X = train_df.drop(columns=['num_orders', 'id', 'meal_id', 'center_id', 'index'], axis=1)\n",
        "    Y = train_df['num_orders']\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
        "\n",
        "    # Define the GradientBoostingRegressor model\n",
        "    model = GradientBoostingRegressor()\n",
        "\n",
        "    # Train the model without hyperparameter tuning\n",
        "    model.fit(X_train, Y_train)\n",
        "    training_data_prediction = model.predict(X_train)\n",
        "    test_data_prediction = model.predict(X_test)\n",
        "    score_2 = metrics.mean_absolute_error(Y_test, test_data_prediction)\n",
        "    print('Mean Absolute Error (No Hyperparameter Tuning): ', score_2)\n",
        "\n",
        "    # Hyperparameter tuning using Grid Search\n",
        "    param_grid = {\n",
        "        'learning_rate': [0.01, 0.1, 0.2,0.3],\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'max_depth': [3, 4, 5,6]\n",
        "    }\n",
        "\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='neg_mean_absolute_error')\n",
        "    grid_search.fit(X_train, Y_train)\n",
        "\n",
        "    best_params_grid = grid_search.best_params_\n",
        "    print('Best Parameters (Grid Search):', best_params_grid)\n",
        "\n",
        "    # Train the model with the best parameters from Grid Search\n",
        "    model_grid = GradientBoostingRegressor(**best_params_grid)\n",
        "    model_grid.fit(X_train, Y_train)\n",
        "    test_data_prediction_grid = model_grid.predict(X_test)\n",
        "    score_grid = metrics.mean_absolute_error(Y_test, test_data_prediction_grid)\n",
        "    print('Mean Absolute Error (Grid Search):', score_grid)\n",
        "\n",
        "    # Hyperparameter tuning using Random Search\n",
        "    param_dist = {\n",
        "        'learning_rate': [0.01, 0.1, 0.2],\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'max_depth': [3, 4, 5]\n",
        "    }\n",
        "\n",
        "    random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=10, cv=3,\n",
        "                                       scoring='neg_mean_absolute_error', random_state=42)\n",
        "    random_search.fit(X_train, Y_train)\n",
        "\n",
        "    best_params_random = random_search.best_params_\n",
        "    print('Best Parameters (Random Search):', best_params_random)\n",
        "\n",
        "    # Train the model with the best parameters from Random Search\n",
        "    model_random = GradientBoostingRegressor(**best_params_random)\n",
        "    model_random.fit(X_train, Y_train)\n",
        "    test_data_prediction_random = model_random.predict(X_test)\n",
        "    score_random = metrics.mean_absolute_error(Y_test, test_data_prediction_random)\n",
        "    print('Mean Absolute Error (Random Search):', score_random)\n",
        "\n",
        "# Call the function with your train_df\n",
        "# gbtrain(train_df)\n",
        "gbtrain(train_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGfiULa9EnpE"
      },
      "source": [
        "# **ExtraTreesRegressor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcjWZLZtESqM",
        "outputId": "f79b5dba-d27d-4d32-a365-401e760ad846"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error (No Hyperparameter Tuning):  73.45413793103448\n",
            "Best Parameters (Grid Search): {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}\n",
            "Mean Absolute Error (Grid Search): 71.66937046061892\n",
            "Best Parameters (Random Search): {'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_depth': None}\n",
            "Mean Absolute Error (Random Search): 71.27766854341978\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from sklearn import metrics\n",
        "\n",
        "def extra_tree_train(train_df):\n",
        "    # Train-test split\n",
        "    X = train_df.drop(columns=['num_orders', 'id', 'meal_id', 'center_id', 'index'], axis=1)\n",
        "    Y = train_df['num_orders']\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
        "\n",
        "    # Define the ExtraTreesRegressor model\n",
        "    model = ExtraTreesRegressor()\n",
        "\n",
        "    # Train the model without hyperparameter tuning\n",
        "    model.fit(X_train, Y_train)\n",
        "    training_data_prediction = model.predict(X_train)\n",
        "    test_data_prediction = model.predict(X_test)\n",
        "    score_2 = metrics.mean_absolute_error(Y_test, test_data_prediction)\n",
        "    print('Mean Absolute Error (No Hyperparameter Tuning): ', score_2)\n",
        "\n",
        "    # Hyperparameter tuning using Grid Search\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100, 150],\n",
        "        'max_depth': [None, 10, 20],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4]\n",
        "    }\n",
        "\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='neg_mean_absolute_error')\n",
        "    grid_search.fit(X_train, Y_train)\n",
        "\n",
        "    best_params_grid = grid_search.best_params_\n",
        "    print('Best Parameters (Grid Search):', best_params_grid)\n",
        "\n",
        "    # Train the model with the best parameters from Grid Search\n",
        "    model_grid = ExtraTreesRegressor(**best_params_grid)\n",
        "    model_grid.fit(X_train, Y_train)\n",
        "    test_data_prediction_grid = model_grid.predict(X_test)\n",
        "    score_grid = metrics.mean_absolute_error(Y_test, test_data_prediction_grid)\n",
        "    print('Mean Absolute Error (Grid Search):', score_grid)\n",
        "\n",
        "    # Hyperparameter tuning using Random Search\n",
        "    param_dist = {\n",
        "        'n_estimators': [50, 100, 150],\n",
        "        'max_depth': [None, 10, 20],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4]\n",
        "    }\n",
        "\n",
        "    random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=10, cv=3,\n",
        "                                       scoring='neg_mean_absolute_error', random_state=42)\n",
        "    random_search.fit(X_train, Y_train)\n",
        "\n",
        "    best_params_random = random_search.best_params_\n",
        "    print('Best Parameters (Random Search):', best_params_random)\n",
        "\n",
        "    # Train the model with the best parameters from Random Search\n",
        "    model_random = ExtraTreesRegressor(**best_params_random)\n",
        "    model_random.fit(X_train, Y_train)\n",
        "    test_data_prediction_random = model_random.predict(X_test)\n",
        "    score_random = metrics.mean_absolute_error(Y_test, test_data_prediction_random)\n",
        "    print('Mean Absolute Error (Random Search):', score_random)\n",
        "\n",
        "# Call the function with your train_df\n",
        "# extra_tree_train(train_df)\n",
        "extra_tree_train(train_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKU0X2QQHG-G"
      },
      "source": [
        "# **AdaBoostRegressort**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSskmMNHHGXs",
        "outputId": "0a3073a4-971b-40fe-9eac-b4e64ef2886d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error (No Hyperparameter Tuning):  80.17630974684995\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn import metrics\n",
        "\n",
        "def adaboost_train(train_df):\n",
        "    # Train-test split\n",
        "    X = train_df.drop(columns=['num_orders', 'id', 'meal_id', 'center_id', 'index'], axis=1)\n",
        "    Y = train_df['num_orders']\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
        "\n",
        "    # Define the AdaBoostRegressor model\n",
        "    model = AdaBoostRegressor()\n",
        "\n",
        "    # Train the model without hyperparameter tuning\n",
        "    model.fit(X_train, Y_train)\n",
        "    training_data_prediction = model.predict(X_train)\n",
        "    test_data_prediction = model.predict(X_test)\n",
        "    score_2 = metrics.mean_absolute_error(Y_test, test_data_prediction)\n",
        "    print('Mean Absolute Error (No Hyperparameter Tuning): ', score_2)\n",
        "\n",
        "    # Hyperparameter tuning using Grid Search\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.01, 0.1, 0.2]\n",
        "    }\n",
        "\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='neg_mean_absolute_error')\n",
        "    grid_search.fit(X_train, Y_train)\n",
        "    return grid_search\n",
        "    best_params_grid = grid_search.best_params_\n",
        "    print('Best Parameters (Grid Search):', best_params_grid)\n",
        "\n",
        "    # Train the model with the best parameters from Grid Search\n",
        "    model_grid = AdaBoostRegressor(**best_params_grid)\n",
        "    model_grid.fit(X_train, Y_train)\n",
        "    test_data_prediction_grid = model_grid.predict(X_test)\n",
        "    score_grid = metrics.mean_absolute_error(Y_test, test_data_prediction_grid)\n",
        "    print('Mean Absolute Error (Grid Search):', score_grid)\n",
        "\n",
        "    # Hyperparameter tuning using Random Search\n",
        "    param_dist = {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.01, 0.1, 0.2]\n",
        "    }\n",
        "\n",
        "    random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=10, cv=3,\n",
        "                                       scoring='neg_mean_absolute_error', random_state=42)\n",
        "    random_search.fit(X_train, Y_train)\n",
        "\n",
        "    best_params_random = random_search.best_params_\n",
        "    print('Best Parameters (Random Search):', best_params_random)\n",
        "\n",
        "    # Train the model with the best parameters from Random Search\n",
        "    model_random = AdaBoostRegressor(**best_params_random)\n",
        "    model_random.fit(X_train, Y_train)\n",
        "    test_data_prediction_random = model_random.predict(X_test)\n",
        "    score_random = metrics.mean_absolute_error(Y_test, test_data_prediction_random)\n",
        "    print('Mean Absolute Error (Random Search):', score_random)\n",
        "\n",
        "# Call the function with your train_df\n",
        "# adaboost_train(train_df)\n",
        "model=adaboost_train(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "1EtWhEYVJxY6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'learning_rate': 0.01, 'n_estimators': 50}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
